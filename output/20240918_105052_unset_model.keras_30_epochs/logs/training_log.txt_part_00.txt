2024-09-18 10:50:52.497626: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-09-18 10:50:52.524583: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-09-18 10:50:53.848914: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-09-18 10:50:53.849041: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-09-18 10:50:53.852064: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-09-18 10:50:53.852182: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-09-18 10:50:53.852300: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-09-18 10:50:53.852409: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-09-18 10:50:53.954861: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-09-18 10:50:53.955044: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-09-18 10:50:53.955174: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-09-18 10:50:53.955268: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-09-18 10:50:53.955351: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-09-18 10:50:53.955452: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-09-18 10:50:53.961417: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-09-18 10:50:53.961562: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-09-18 10:50:53.961664: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-09-18 10:50:53.961762: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-09-18 10:50:53.961852: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-09-18 10:50:53.961931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14096 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9
2024-09-18 10:50:53.962162: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-09-18 10:50:53.962251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14173 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4070 Ti SUPER, pci bus id: 0000:04:00.0, compute capability: 8.9
2024-09-18 10:50:55.707220: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorSliceDataset/_1"
op: "TensorSliceDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_STRING
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 4
  }
}
attr {
  key: "is_files"
  value {
    b: false
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\024TensorSliceDataset:0"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
attr {
  key: "replicate_on_split"
  value {
    b: false
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_STRING
        }
      }
    }
  }
}

Number of devices: 2
Failed to send notification.
Epoch 1/30
2024-09-18 10:50:58.440803: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600
2024-09-18 10:50:58.448447: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600
2024-09-18 10:50:59.946336: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7c965405a9f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-09-18 10:50:59.946361: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Ti SUPER, Compute Capability 8.9
2024-09-18 10:50:59.946365: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 4070 Ti SUPER, Compute Capability 8.9
2024-09-18 10:50:59.949578: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-09-18 10:51:00.023070: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
1/1 [==============================] - ETA: 0s - loss: 0.08162024-09-18 10:51:02.028217: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorSliceDataset/_1"
op: "TensorSliceDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_STRING
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 4
  }
}
attr {
  key: "is_files"
  value {
    b: false
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\024TensorSliceDataset:1"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
attr {
  key: "replicate_on_split"
  value {
    b: false
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_STRING
        }
      }
    }
  }
}

2024-09-18 10:51:02.396349: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
1/1 [==============================] - 7s 7s/step - loss: 0.0816 - val_loss: 0.0913
Epoch 2/30
1/1 [==============================] - ETA: 0s - loss: 0.08081/1 [==============================] - 0s 166ms/step - loss: 0.0808 - val_loss: 0.0901
Epoch 3/30
1/1 [==============================] - ETA: 0s - loss: 0.07991/1 [==============================] - 0s 168ms/step - loss: 0.0799 - val_loss: 0.0887
Epoch 4/30
1/1 [==============================] - ETA: 0s - loss: 0.07891/1 [==============================] - 0s 178ms/step - loss: 0.0789 - val_loss: 0.0872
Epoch 5/30
1/1 [==============================] - ETA: 0s - loss: 0.07771/1 [==============================] - 0s 167ms/step - loss: 0.0777 - val_loss: 0.0849
Epoch 6/30
1/1 [==============================] - ETA: 0s - loss: 0.07591/1 [==============================] - 0s 168ms/step - loss: 0.0759 - val_loss: 0.0814
Epoch 7/30
1/1 [==============================] - ETA: 0s - loss: 0.07341/1 [==============================] - 0s 167ms/step - loss: 0.0734 - val_loss: 0.0759
Epoch 8/30
1/1 [==============================] - ETA: 0s - loss: 0.06981/1 [==============================] - 0s 173ms/step - loss: 0.0698 - val_loss: 0.0683
Epoch 9/30
1/1 [==============================] - ETA: 0s - loss: 0.06621/1 [==============================] - 0s 168ms/step - loss: 0.0662 - val_loss: 0.0633
Epoch 10/30
1/1 [==============================] - ETA: 0s - loss: 0.06861/1 [==============================] - 0s 167ms/step - loss: 0.0686 - val_loss: 0.0610
Epoch 11/30
1/1 [==============================] - ETA: 0s - loss: 0.06411/1 [==============================] - 0s 167ms/step - loss: 0.0641 - val_loss: 0.0611
Epoch 12/30
1/1 [==============================] - ETA: 0s - loss: 0.06101/1 [==============================] - 0s 168ms/step - loss: 0.0610 - val_loss: 0.0610
Epoch 13/30
1/1 [==============================] - ETA: 0s - loss: 0.05951/1 [==============================] - 0s 169ms/step - loss: 0.0595 - val_loss: 0.0584
Epoch 14/30
1/1 [==============================] - ETA: 0s - loss: 0.05721/1 [==============================] - 0s 186ms/step - loss: 0.0572 - val_loss: 0.0537
Epoch 15/30
1/1 [==============================] - ETA: 0s - loss: 0.05421/1 [==============================] - 0s 166ms/step - loss: 0.0542 - val_loss: 0.0473
Epoch 16/30
1/1 [==============================] - ETA: 0s - loss: 0.05061/1 [==============================] - 0s 186ms/step - loss: 0.0506 - val_loss: 0.0408
Epoch 17/30
1/1 [==============================] - ETA: 0s - loss: 0.04741/1 [==============================] - 0s 171ms/step - loss: 0.0474 - val_loss: 0.0364
Epoch 18/30
1/1 [==============================] - ETA: 0s - loss: 0.04261/1 [==============================] - 0s 168ms/step - loss: 0.0426 - val_loss: 0.0337
Epoch 19/30
1/1 [==============================] - ETA: 0s - loss: 0.03791/1 [==============================] - 0s 168ms/step - loss: 0.0379 - val_loss: 0.0296
Epoch 20/30
1/1 [==============================] - ETA: 0s - loss: 0.03361/1 [==============================] - 0s 171ms/step - loss: 0.0336 - val_loss: 0.0233
Epoch 21/30
1/1 [==============================] - ETA: 0s - loss: 0.02881/1 [==============================] - 0s 167ms/step - loss: 0.0288 - val_loss: 0.0186
Epoch 22/30
1/1 [==============================] - ETA: 0s - loss: 0.02451/1 [==============================] - 0s 179ms/step - loss: 0.0245 - val_loss: 0.0148
Epoch 23/30
1/1 [==============================] - ETA: 0s - loss: 0.01971/1 [==============================] - 0s 168ms/step - loss: 0.0197 - val_loss: 0.0118
Epoch 24/30
1/1 [==============================] - ETA: 0s - loss: 0.01641/1 [==============================] - 0s 170ms/step - loss: 0.0164 - val_loss: 0.0113
Epoch 25/30
1/1 [==============================] - ETA: 0s - loss: 0.01491/1 [==============================] - 0s 189ms/step - loss: 0.0149 - val_loss: 0.0111
Epoch 26/30
1/1 [==============================] - ETA: 0s - loss: 0.01451/1 [==============================] - 0s 169ms/step - loss: 0.0145 - val_loss: 0.0114
Epoch 27/30
1/1 [==============================] - ETA: 0s - loss: 0.01481/1 [==============================] - 0s 171ms/step - loss: 0.0148 - val_loss: 0.0116
Epoch 28/30
1/1 [==============================] - ETA: 0s - loss: 0.01421/1 [==============================] - 0s 168ms/step - loss: 0.0142 - val_loss: 0.0102
Epoch 29/30
1/1 [==============================] - ETA: 0s - loss: 0.01281/1 [==============================] - 0s 167ms/step - loss: 0.0128 - val_loss: 0.0083
Epoch 30/30
1/1 [==============================] - ETA: 0s - loss: 0.01161/1 [==============================] - 0s 169ms/step - loss: 0.0116 - val_loss: 0.0093
2024-09-18 10:51:09.222988: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorSliceDataset/_1"
op: "TensorSliceDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_STRING
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 5
  }
}
attr {
  key: "is_files"
  value {
    b: false
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\024TensorSliceDataset:2"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
attr {
  key: "replicate_on_split"
  value {
    b: false
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_STRING
        }
      }
    }
  }
}

1/1 [==============================] - ETA: 0s - loss: 0.05231/1 [==============================] - 0s 270ms/step - loss: 0.0523
Test Loss: 0.05229439586400986
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 342ms/step
/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Overall F1 Score: 0.0, Precision: 0.0, Recall: 0.0
Failed to send notification.
